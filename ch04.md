# ニューラルネットワークの学習

# 4.3 数値微分

- 勾配の性質について

# 4.3.1 微分

- 「ある瞬間」の変化の量を表したもの
- 0に無限に近い値にするために、小さすぎる値を設定すると**丸め誤差**が起こってしまう
	- 10e-4程度の値を用いるといい結果が得られる
- 数値微分の誤差を減らす工夫として、中心差分を計算する(xを中心とした前後の差分)


# 4.3.3 偏微分

- 複数の変数からなる関数の微分を**偏微分**という


# 4.4 勾配

- 全ての変数の偏微分をベクトルとして纏めたものを**勾配**という
- 勾配が示す方向は、各場所において**関数の値を最も減らす方法**

# 4.4.1 勾配法

- 機会学習の最適なパラメーターは損失関数が最小値を取る時のパラメーターの値
- 勾配方向に繰り返し移動を進めることで、関数の値を徐々に減らすのが**勾配法**です

# 4.5 学習アルゴリズムの実装

- ニューラルネットワークの学習手順
	- ステップ1(ミニバッチ)
	- ステップ2(勾配の算出)
	- ステップ3(パラメータの更新)
	- ステップ4(1,2,3のステップを繰り返す)

# 4.5.1 2層ニューラルネットワークのクラス
- [ソースコード](https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch04/two_layer_net.py)


# 4.5.2 ミニバッチ学習の実装
- [ソースコード](https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch04/train_neuralnet.py)


# 4.5.3 テストデータで評価


# 参考

- [『ゼロから作る Deep Learning』のリポジトリ](https://github.com/oreilly-japan/deep-learning-from-scratch/tree/master/ch04)
